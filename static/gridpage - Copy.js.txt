// --- Global Variables ---
let currentlyScannedButton = null; // Tracks the currently highlighted button
let lastGamepadInputTime = 0; // For gamepad debounce/rate limiting
let querytype = null; // Stores the type of query (e.g., 'question', 'currentevents')
let eventtype = null; // Stores specific event type if needed
let isLLMProcessing = false; // Flag to detect if LLM query is running
const clickDebounceDelay = 300; // Debounce for button clicks (adjust as needed)
let defaultDelay = 3500; // Default auditory scan delay (ms) - Loaded from settings
let currentQuestion = null; // Stores the current question context for LLM
let scanningInterval; // Holds the interval ID for scanning
let currentButtonIndex = -1; // Tracks the index for scanning
let gamepadIndex = null; // To store the index of the connected gamepad
let gamepadPollInterval = null; // Interval ID for gamepad polling
const ANNOUNCE_RELOAD_DELAY = 2000; // Delay in ms after announce before reload (adjust as needed)
// --- NEW: Wake Word Variables ---
let wakeWordInterjection = "hey"; // Default interjection (lowercase)
let wakeWordName = "bravo";       // Default name (lowercase)
let LLMOptions = 10; // Default number of options to generate
let ScanningOff = false; // Default scanning state
let SummaryOff = false; // Default summary state
const QUESTION_TEXTAREA_ID = 'question-display'; // ID of the question textarea
const LISTENING_HIGHLIGHT_CLASS = 'highlight-listening'; // CSS class for highlighting
let activeOriginatingButtonText = null; // NEW: To store the text of the button that initiated the LLM query
let activeLLMPromptForContext = null; // Store the prompt that generated current LLM buttons

// --- NEW GLOBAL VARIABLES FOR ANNOUNCEMENT QUEUE & AUDIO CONTEXT FIX ---
let announcementQueue = [];       // Queue for sequential announcements
let isAnnouncingNow = false;      // Flag to prevent concurrent announce playback
let audioContextResumeAttempted = false; // Flag for AudioContext auto-resume helper

// --- NEW: User Management Variables ---
let currentUserId = "default_user"; // Default user for initial PoC. Will try to load from session storage.
const USER_ID_SESSION_KEY = "currentUserId"; // Key for storing user ID in session storage
const SPEECH_HISTORY_LOCAL_STORAGE_KEY = (userId) => `speechHistory_${userId}`; // Function for dynamic key
const CHAT_HISTORY_LOCAL_STORAGE_KEY = (userId) => `chatHistory_${userId}`; // Renamed from CHAT_HISTORY_JSON_FILE

// --- Server URL (MUST BE this for GCP, already in your attached file) ---
const SERVER_URL = "https://talkwithbravo.com"; 

// --- Global Audio Settings (Client-Side, as per your attached file) ---
let personalSpeakerId = localStorage.getItem('bravoPersonalSpeakerId') || 'default';
let systemSpeakerId = localStorage.getItem('bravoSystemSpeakerId') || 'default';


// --- Utility to convert Base64 to ArrayBuffer (Needed for playing audio) ---
function base64ToArrayBuffer(base64) {
    const binaryString = atob(base64);
    const len = binaryString.length;
    const bytes = new Uint8Array(len);
    for (let i = 0; i < len; i++) {
        bytes[i] = binaryString.charCodeAt(i);
    }
    return bytes.buffer;
}


// --- Settings Loading ---
async function loadScanSettings() {
    try {
       const response = await fetch('/api/settings', {
      headers: {
        'X-User-ID': currentUserId // <-- ADD THIS LINE
      }
    });
       
       if (!response.ok) {
            const errorText = await response.text();
            console.error(`HTTP error loading settings! status: ${response.status} ${errorText}`);
            // Keep default values if fetch fails
            wakeWordInterjection = "hey";
            wakeWordName = "bravo";
            defaultDelay = 3500;
            LLMOptions = 10;
            ScanningOff = false;
            SummaryOff = false;

            return;
       }
       

       const settings = await response.json();

       // Load Scan Delay
       if (settings && typeof settings.scanDelay === 'number' && !isNaN(settings.scanDelay)) {
            const loadedDelay = parseInt(settings.scanDelay);
            defaultDelay = Math.max(100, loadedDelay); // Ensure minimum delay
            console.log(`Auditory scan delay loaded: ${defaultDelay}ms`);
       } else {
            console.warn("Scan delay setting not found or invalid in response. Using default:", defaultDelay);
            defaultDelay = 3500; // Ensure default if invalid
       }

       // Load Wake Word parts
       if (settings && typeof settings.wakeWordInterjection === 'string' && settings.wakeWordInterjection.trim()) {
           wakeWordInterjection = settings.wakeWordInterjection.trim().toLowerCase(); // Store lowercase
           console.log(`Wake Word Interjection loaded: "${wakeWordInterjection}"`);
       } else {
            console.warn("Wake Word Interjection not found/invalid. Using default:", wakeWordInterjection);
            // Ensure default is set if loaded value is null/empty after trim
            wakeWordInterjection = "hey";
       }
        if (settings && typeof settings.wakeWordName === 'string' && settings.wakeWordName.trim()) {
           wakeWordName = settings.wakeWordName.trim().toLowerCase(); // Store lowercase
           console.log(`Wake Word Name loaded: "${wakeWordName}"`);
       } else {
            console.warn("Wake Word Name not found/invalid. Using default:", wakeWordName);
            // Ensure default is set if loaded value is null/empty after trim
            wakeWordName = "bravo";
       }
       console.log("LLM Options after fetch:", settings.LLMOptions);
       if (settings && typeof settings.LLMOptions === 'number' && !isNaN(settings.LLMOptions)) {
            const loadedLLMOptions = parseInt(settings.LLMOptions);
            LLMOptions = Math.max(1, loadedLLMOptions); // Ensure minimum options
            console.log(`LLM Options loaded: ${LLMOptions}`);
       } else {
            console.warn("LLM Options setting not found or invalid in response. Using default:", LLMOptions);
            LLMOptions = 10; // Ensure default if invalid
       }
       if (settings && typeof settings.ScanningOff === 'boolean') {
            ScanningOff = settings.ScanningOff;
            console.log(`Scanning Off setting loaded: ${ScanningOff}`);
       } else {
            console.warn("Scanning Off setting not found or invalid in response. Using default:", ScanningOff);
            ScanningOff = false; // Ensure default if invalid   
         }
         if (settings && typeof settings.SummaryOff === 'boolean') {
            SummaryOff = settings.SummaryOff;
            console.log(`Summary Off setting loaded: ${SummaryOff}`);       
         }  
        else {      
            console.warn("Summary Off setting not found or invalid in response. Using default:", SummaryOff);
            SummaryOff = false; // Ensure default if invalid
        }



   } catch (error) {
       console.error('Error fetching or parsing scan settings:', error);
       // Keep default values on error
       defaultDelay = 3500;
       wakeWordInterjection = "hey";
       wakeWordName = "bravo";
        LLMOptions = 10;
       ScanningOff = false;
       SummaryOff = false;
   }
}



// --- Banner and Page Title Functions (Moved from gridpage.html) ---
function capitalizeFirstLetter(string) {
    if (!string) return "";
    return string.charAt(0).toUpperCase() + string.slice(1).toLowerCase();
}

function setBannerAndPageTitle() {
    const urlParams = new URLSearchParams(window.location.search);
    const pageQueryParam = urlParams.get('page');
    const bannerTitleElement = document.getElementById('dynamic-page-title');
    let displayTitle = "Grid"; // Default title

    console.log("[gridpage.js] setBannerAndPageTitle called.");
    const storedBannerTitle = sessionStorage.getItem('dynamicBannerTitle');
    console.log("[gridpage.js] Value from sessionStorage.getItem('dynamicBannerTitle'):", storedBannerTitle);

    if (storedBannerTitle) {
        displayTitle = storedBannerTitle;
        sessionStorage.removeItem('dynamicBannerTitle'); // Clear it after use
        console.log("[gridpage.js] Using stored banner title from sessionStorage:", displayTitle);
        console.log("[gridpage.js] sessionStorage after removeItem:", JSON.stringify(sessionStorage));
    } else if (pageQueryParam) {
        displayTitle = capitalizeFirstLetter(pageQueryParam);
        console.log("[gridpage.js] No stored title. Using page query param for banner title:", displayTitle);
    } else {
        console.log("[gridpage.js] No stored title and no page query param. Using default banner title 'Grid'.");
    }

    console.log("[gridpage.js] Final displayTitle for banner:", displayTitle);
    if (bannerTitleElement) { bannerTitleElement.textContent = displayTitle; }
    document.title = displayTitle; // Update browser tab title
}


// --- Helper to get current page information from URL ---
function getCurrentPageInfo() {
    const params = new URLSearchParams(window.location.search);
    const pageNameFromUrl = params.get('page');
    const categoryFromUrl = params.get('category');
    const topicFromUrl = params.get('topic'); // For dynamic topics

    if (pageNameFromUrl) {
        return { name: pageNameFromUrl, type: "static" };
    } else if (categoryFromUrl) {
        // For dynamic pages like current events, the "page name" can be the category.
        return { name: categoryFromUrl, type: "category" };
    } else if (topicFromUrl) {
        return { name: topicFromUrl, type: "dynamic_topic" };
    }
    return { name: "UnknownPage", type: "unknown" }; // Fallback
}


// --- User Management Functions ---
// Called to load the current user state, including UI updates and refreshing local data
async function loadCurrentUserState() {
    const storedUserId = sessionStorage.getItem(USER_ID_SESSION_KEY);
    if (storedUserId) {
        currentUserId = storedUserId;
    } else {
        // If no user ID in session storage, set 'default_user' and store it
        currentUserId = "default_user";
        sessionStorage.setItem(USER_ID_SESSION_KEY, currentUserId);
        console.log(`No user ID found in session. Defaulting to '${currentUserId}' and storing.`);
    }

    // Update the UI to show the active user ID
    const activeUserIdElement = document.getElementById('active-user-id-value');
    if (activeUserIdElement) {
        activeUserIdElement.textContent = currentUserId;
    }
    const userIdInput = document.getElementById('user-id-selector');
    if (userIdInput) {
        userIdInput.value = currentUserId;
    }

    console.log(`Active User ID is: ${currentUserId}`);

    // Reload UI for the new user (This effectively re-triggers DOMContentLoaded logic for dynamic content)
    // For local storage items, load the *user-specific* history
    const speechHistoryElement = document.getElementById('speech-history');
    if (speechHistoryElement) {
        speechHistoryElement.value = localStorage.getItem(SPEECH_HISTORY_LOCAL_STORAGE_KEY(currentUserId)) || '';
    }

    // You might want to reload the entire page after setting a new user,
    // to ensure all page elements (like settings, initial grid) are loaded for the new user.
    // window.location.reload(true); // Uncomment this if you want a full page reload on user switch
    // For now, let's just log and update local parts. The main grid load will happen via DOMContentLoaded.
}

async function handleSetUser() {
    const userIdInput = document.getElementById('user-id-selector');
    const newUserId = userIdInput.value.trim();

    if (!newUserId) {
        alert("User ID cannot be empty!");
        return;
    }
    if (newUserId === currentUserId) {
        console.log(`User ID already set to '${newUserId}'. No change.`);
        return;
    }

    console.log(`Attempting to set user ID to: ${newUserId}`);
    sessionStorage.setItem(USER_ID_SESSION_KEY, newUserId);
    // Reload the page to fully apply the new user context across all data fetches
    window.location.reload(true);
}

async function handleCreateUser() {
    const userIdInput = document.getElementById('user-id-selector');
    const newUserId = userIdInput.value.trim();

    if (!newUserId) {
        alert("Please enter a User ID to create.");
        return;
    }

    document.getElementById('loading-indicator').style.display = 'flex'; // Show loading

    try {
        const response = await fetch(`/create-user/${newUserId}`, {
            method: 'POST',
            // No headers required for this simple endpoint, as it's for user creation
        });

        if (!response.ok) {
            const errorData = await response.json();
            throw new Error(errorData.detail || `Failed to create user: ${response.status}`);
        }

        const data = await response.json();
        alert(data.message);
        console.log("User creation response:", data);
        sessionStorage.setItem(USER_ID_SESSION_KEY, newUserId);
        window.location.reload(true); // Reload to load the new user's context
    } catch (error) {
        console.error("Error creating user:", error);
        alert(`Error creating user: ${error.message}`);
    } finally {
        document.getElementById('loading-indicator').style.display = 'none';
    }
}


// --- DOMContentLoaded Initialization ---
document.addEventListener('DOMContentLoaded', async () => {
    // 1. Load the current user state first (this also sets currentUserId)
    await loadCurrentUserState();

    // 2. Load scan settings (these now use currentUserId implicitly via fetch)
    await loadScanSettings();

    // 3. Add event listeners for user selection buttons
    const setUserButton = document.getElementById('set-user-id-button');
    if (setUserButton) {
        setUserButton.addEventListener('click', handleSetUser);
    }
    const createNewUserButton = document.getElementById('create-user-button');
    if (createNewUserButton) {
        createNewUserButton.addEventListener('click', handleCreateUser);
    }

    const gridContainer = document.getElementById('gridContainer');
    const params = new URLSearchParams(window.location.search);
    let  pageName = params.get('page');

    // If no specific page is requested (e.g., first loading the app, default to "home")
    if (!pageName) {
        pageName = "home";
        // Optionally update the URL to reflect the default page for cleaner history
        // history.replaceState(null, '', `?page=home`); // Uncomment if you want clean URLs
    }

    // This setBannerAndPageTitle function will be called later, after we load the actual page data
    // setBannerAndPageTitle(); // REMOVE or COMMENT OUT this line from here for now

    try {
        // Now fetch user-specific pages from the backend endpoint
        const response = await fetch('/pages', {
            headers: {
                'X-User-ID': currentUserId // <--- CRUCIAL: ADD THIS HEADER
            }
        });
        if (!response.ok) {
            const errorText = await response.text();
            throw new Error(`Failed to load user pages: ${response.status} - ${errorText}`);
        }
        const userPages = await response.json(); // Renamed from 'pages' to 'userPages' to avoid conflict on line 125

        // Find the specific page object for the requested pageName
        let page = userPages.find(p => p.name === pageName); 

        // If the requested page is not found (e.g., deleted, or wrong URL parameter)
        // and if a 'home' page exists, default to it. If not, default to the first page.
        if (!page) {
            const homePage = userPages.find(p => p.name === "home");
            if (homePage) {
                page = homePage;
                console.warn(`Requested page '${pageName}' not found for user ${currentUserId}. Defaulting to 'home' page.`);
            } else if (userPages.length > 0) {
                page = userPages[0];
                console.warn(`Requested page '${pageName}' not found. Defaulting to first available page: '${page.name}' for user ${currentUserId}.`);
            } else {
                console.error(`No pages found for user ${currentUserId}. Cannot display any content.`);
                gridContainer.innerHTML = `<p class="col-span-full text-center text-red-500">Error: No pages found for user ${currentUserId}.</p>`;
                return; // Stop further processing
            }
        }

        // --- Now set the banner title using the loaded page's display name ---
        // Ensure setBannerAndPageTitle function is correctly reading from sessionStorage after we call it.
        // And populate the grid based on the 'page' object
        if (page.displayName) {
             sessionStorage.setItem('dynamicBannerTitle', page.displayName);
             setBannerAndPageTitle(); // Update the banner NOW
        } else {
             // If displayName is missing, fall back to page.name and capitalize it
             sessionStorage.setItem('dynamicBannerTitle', capitalizeFirstLetter(page.name));
             setBannerAndPageTitle();
        }

        generateGrid(page, gridContainer); // Generates grid based on the selected 'page' object

        // Handle URL 'options' parameter (for dynamic LLM options on initial load)
        const optionsParam = params.get('options');
        if (optionsParam) {
            const options = decodeURIComponent(optionsParam).split('\n')
                .map((option) => option.replace(/^\d+\.\s*|\\|['"]+|^\(+\d\s*/g, '').replace('1. ', '').trim())
                .filter(Boolean);
            if (options.length > 0) {
                const optionsObjects = options.map(optText => ({ summary: optText, option: optText }));
                console.log("Generating LLM buttons from URL params:", optionsObjects);
                generateLlmButtons(optionsObjects); 
            } else {
                console.warn("Options parameter found but resulted in empty options array.");
            }
        }
    } catch (error) {
        console.error('Error loading page data:', error);
        gridContainer.innerHTML = `<p class="col-span-full text-center text-red-500">Error loading page data for user ${currentUserId}: ${error.message}.</p>`;
    }

    // --- Setup Input Listeners ---
    setupKeyboardListener(); // Ensure called
    setupGamepadListeners(); // Ensure called

    // --- Setup Speech Recognition ---
    setupSpeechRecognition();

    // --- Add AudioContext Resume Listeners (MUST HAVE for playing audio) ---
    document.body.addEventListener('mousedown', tryResumeAudioContext, { once: true });
    document.body.addEventListener('touchstart', tryResumeAudioContext, { once: true });
    document.body.addEventListener('keydown', tryResumeAudioContext, { once: true }); // Keyboard also counts as gesture

    // --- Setup Clear History Button ---
    const clearButton = document.getElementById('clear-history');
    const speechHistory = document.getElementById('speech-history');
    if (clearButton && speechHistory) {
        clearButton.addEventListener('click', () => {
            speechHistory.value = '';
            localStorage.removeItem('speechHistory');
        });
    } else {
        console.error("Could not find clear-history button or speech-history textarea.");
    }
    // Initial load of user-specific speech history (redundant due to loadCurrentUserState, but harmless)
    if (speechHistory) {
      const storedHistory = localStorage.getItem(SPEECH_HISTORY_LOCAL_STORAGE_KEY(currentUserId)); // Use user-specific key
      if (storedHistory) { speechHistory.value = storedHistory; }
    }

    
});

// --- Debounce Function ---
function debounce(func, delay) {
    let timeoutId;
    return function(...args) {
        const context = this;
        clearTimeout(timeoutId);
        timeoutId = setTimeout(() => {
            func.apply(context, args);
        }, delay);
    };
}

// --- Grid Generation ---
function generateGrid(page, container) {
    container.innerHTML = '';

    const baseGridButtonClasses = [ 'grid-button-base', 'w-full', 'h-24', 'sm:h-28', 'md:h-32', 'text-white', 'font-semibold', 'text-sm', 'sm:text-base', 'p-2', 'rounded-lg', 'shadow-md', 'border-2', 'transition', 'duration-150', 'ease-in-out', 'transform', 'hover:-translate-y-0.5', 'flex', 'items-center', 'justify-center', 'text-center', 'cursor-pointer', 'focus:outline-none', 'focus:ring-2', 'focus:ring-offset-2'];
    const defaultGridButtonColors = [ 'bg-blue-600', 'border-blue-800', 'hover:bg-blue-700', 'hover:border-blue-900', 'focus:ring-blue-500'];

    const buttonsToDisplay = page.buttons.filter(buttonData => buttonData.text && buttonData.text.trim() !== '');
    if (buttonsToDisplay.length === 0) {
         container.innerHTML = `<p class="col-span-full text-center text-gray-500">No buttons configured.</p>`;
         return;
    }

    buttonsToDisplay.forEach(buttonData => {
        console.log(`Processing button: "${buttonData.text}", Hidden property value: [${buttonData.hidden}], Type: [${typeof buttonData.hidden}]`);
         // If button is marked as hidden, skip creating it
         if (buttonData.hidden === true) {
            console.log(`Button "${buttonData.text}" is hidden (hidden === true), SKIPPING.`);
            return; // Equivalent to 'continue' in a forEach loop context
        }
        const button = document.createElement('button');
        button.textContent = buttonData.text;
        button.dataset.llmQuery = buttonData.LLMQuery || '';
        button.dataset.targetPage = buttonData.targetPage || '';
        button.dataset.speechPhrase = buttonData.speechPhrase || ''; // Use text as fallback
        button.dataset.queryType = buttonData.queryType || '';
        button.className = [...baseGridButtonClasses, ...defaultGridButtonColors].join(' ');
        button.addEventListener('click', debounce(() => handleButtonClick(buttonData), clickDebounceDelay));
        container.appendChild(button);
    });

    startAuditoryScanning();
}

// --- Button Click Handling ---
async function handleButtonClick(buttonData) {

    const clickTimestamp = new Date().toISOString();
    const pageInfo = getCurrentPageInfo();

    const localQueryType = buttonData.queryType || '';
    const llmQuery = buttonData.LLMQuery || '';
    const targetPage = buttonData.targetPage || '';
    const speechPhrase = buttonData.speechPhrase || ''; // The phrase to announce

    // For LLM-generated buttons, buttonData is the option object {option, summary, isLLMGenerated, originalPrompt}
    // For static buttons, buttonData is from pages.json {text, LLMQuery, targetPage, etc.}
    const buttonLabel = buttonData.option || buttonData.text || ''; // Use .option for LLM, .text for static
    const buttonSummary = buttonData.summary || buttonLabel; // Use .summary for LLM, label for static

    // Determine the correct context for the audit log
    // For originating_button_text: if it's an LLM generated button, its data will have originatingButtonText.
    // Otherwise (static button), it's null as it's the originator itself or a simple action.
    let contextForLog;
    if (buttonData.isLLMGenerated) {
        contextForLog = buttonData.originalPrompt; // This will be the concise original prompt
    } else if (llmQuery) { // Static button that will trigger LLM
        contextForLog = llmQuery; // The concise prompt defined on this button
    } else { // Static button, no LLM action (navigation, simple speak)
        activeOriginatingButtonText = null; // Reset for non-LLM generating actions
        contextForLog = pageInfo.name; // Context is the current page name
    }

    // --- Log Button Click for Audit ---
    const logData = {
        timestamp: clickTimestamp,
        page_name: pageInfo.name,
        page_context_prompt: contextForLog,
        button_text: buttonLabel,
        button_summary: buttonSummary,
        is_llm_generated: buttonData.isLLMGenerated || false,
        originating_button_text: buttonData.isLLMGenerated ? buttonData.originatingButtonText : null
    };

    try {
        console.log("Sending button click log:", logData);
        const response = await fetch('/api/audit/log-button-click', {
            method: 'POST',
            headers: {
        'Content-Type': 'application/json',
        'X-User-ID': currentUserId // <-- ADD THIS LINE
      },
            body: JSON.stringify(logData)
        });
        if (!response.ok) console.error("Failed to log button click:", response.status, await response.text());
        else console.log("Button click logged successfully:", logData);
    } catch (error) {
        console.error("Error sending button click log:", error);
    }


    console.log("Button Clicked Data:", buttonData);
    stopAuditoryScanning();

    if (llmQuery) {

        if (speechPhrase) {
            console.log(`Announcing phrase: "${speechPhrase}"`);
            announce(speechPhrase, "system"); // Announce first
        }

        // --- Store the button's label and update banner immediately ---
        if (buttonLabel) {
            sessionStorage.setItem('dynamicBannerTitle', buttonLabel);
            console.log(`[gridpage.js] Stored in sessionStorage 'dynamicBannerTitle': '${buttonLabel}'`);
            setBannerAndPageTitle(); // Update banner NOW
        }

        

        isLLMProcessing = true;
        querytype = localQueryType; // querytype is already a global, ensure it's intended
        activeOriginatingButtonText = buttonLabel; // Set the originating button text

        activeLLMPromptForContext = llmQuery; // Set context to the concise prompt from button data
        // Replace '#LLMOptions' with Global LLMOptions
        const llmQueryWithOptions = llmQuery.replace(/#LLMOptions/g, LLMOptions);
        currentQuestion = llmQueryWithOptions;

        // Conditionally construct the summary instruction
        const summaryInstruction = SummaryOff
            ? 'The "summary" key should contain the exact same FULL text as the "option" key.'
            : 'If the generated option is more than 5 words, the "summary" key should be a 3-5 word abbreviation of each option, including the exact key words from the option. If the option is 5 words or less, the "summary" key should contain the exact same FULL text as the "option" key.';

        const promptForLLM = `
            "${llmQueryWithOptions}".
            Format your response as a JSON list where each item has "option" and "summary" keys.
            The "option" key should contain the FULL option text. If the option contains a question and answer, like a joke, the option contain the question and the answer.
            ${summaryInstruction}
            Example: [{"option": "...", "summary": "..."}]
            VERY IMPORTANT: Do not include any introductory or concluding text in your response, even a disclaimer.
        `;
        document.getElementById('loading-indicator').style.display = 'flex';
        try {
            const options = await getLLMResponse(promptForLLM);
            console.log("LLM response processed in handleButtonClick:", options);

            if (Array.isArray(options)) {
                 if (options.length === 0 || options.every(o => typeof o === 'object' && o !== null && 'option' in o && 'summary' in o)) {
                    generateLlmButtons(options);
                 } else {
                    console.error("LLM response array contained invalid objects:", options);
                    announce("Sorry, I received an unexpected response format.", "system", false);
                    startAuditoryScanning();
                 }
            } else {
                 console.error("LLM response was not an array:", options); // Should not happen now
                 announce("Sorry, I received an unexpected response.", "system", false);
                 startAuditoryScanning();
            }
        } catch (error) {
             console.error("Error getting or processing LLM response in handleButtonClick:", error);
             announce("Sorry, there was an error getting the response.", "system", false);
             startAuditoryScanning();
        } finally {
            document.getElementById('loading-indicator').style.display = 'none';
            isLLMProcessing = false;
        }
    } else if (localQueryType === "currentevents") {
        // --- Store the button's label and update banner for current events ---
        if (buttonLabel) {
            sessionStorage.setItem('dynamicBannerTitle', buttonLabel);
            console.log(`[gridpage.js] Stored in sessionStorage 'dynamicBannerTitle': '${buttonLabel}'`);
            setBannerAndPageTitle(); // Update banner NOW
            activeLLMPromptForContext = `User is viewing current events for category: ${buttonData.text.toLowerCase()}`;
            activeOriginatingButtonText = buttonLabel; // Set for current events originating button
        }
        isLLMProcessing = true; querytype = localQueryType; eventtype = buttonData.text.toLowerCase();
        await getCurrentEvents(eventtype);
        // Reset isLLMProcessing after current events are handled
        isLLMProcessing = false;
    } else if (targetPage) {
        // This is a direct navigation button
        console.log(`Button with targetPage: ${targetPage}. Announcing phrase: "${speechPhrase}"`);
        activeOriginatingButtonText = null; // Reset on navigation
        if (speechPhrase) {
            await announce(speechPhrase, "system"); // Announce first
        }
        // Delay navigation using defaultDelay
        // Auditory scanning is already stopped from the beginning of handleButtonClick.
        // Gamepad and keyboard inputs are guarded by currentlyScannedButton, isLLMProcessing, and listeningForQuestion flags.
        console.log(`Delaying navigation to ${targetPage} by ${defaultDelay}ms.`);
        setTimeout(() => {
            console.log(`Navigating to page: ${targetPage} after delay.`);
            window.location.href = `gridpage.html?page=${targetPage}`;
        }, defaultDelay);
        // NOTE: No startAuditoryScanning() here, as we are navigating away.
        // The new page will initialize its own scanning if needed.
    } else if (speechPhrase) {
        activeOriginatingButtonText = null; // Reset for simple speak actions
        console.log(`Announcing phrase: ${speechPhrase}`);
        await announce(speechPhrase, "system");
        startAuditoryScanning();
        
    } else {
        activeOriginatingButtonText = null; // Reset
        console.warn("Button clicked with no action defined:", buttonData); startAuditoryScanning();
    }
}

// --- Chat History ---
async function recordChatHistory(question, response) {
    try {
        const recorded = await fetch('/record_chat_history', {
            method: 'POST',
            headers: {
        'Content-Type': 'application/json',
        'X-User-ID': currentUserId // <-- ADD THIS LINE
      },
            body: JSON.stringify({ question, response })
        });
        if (!recorded.ok) {
            throw new Error(`HTTP error! status: ${recorded.status}`);
        }

        console.log("Chat history recorded successfully.");
    } catch (error) {
        console.error("Error recording chat history:", error);
    }
}

// --- Current Events ---
async function getCurrentEvents(eventType) {
    console.log(`Workspaceing current events for type: ${eventType}`); // Log the event type being requested
    document.getElementById('loading-indicator').style.display = 'flex'; // Show loading indicator
    
    try { // Added try...catch for better error handling
        const response = await fetch('/get-current-events', {
            method: 'POST',
            headers: {
        'Content-Type': 'application/json',
        'X-User-ID': currentUserId // <-- ADD THIS LINE
      },
            body: JSON.stringify({ eventType }),
        });

        // Check if the HTTP request itself was successful (e.g., status 200 OK)
        if (!response.ok) {
            // Try to get error details from the response body if available
            let errorDetails = `HTTP error! status: ${response.status}`;
            try {
                const errorText = await response.text(); // Read error response body
                errorDetails += `, Body: ${errorText}`;
            } catch (e) {
                // Ignore error reading body if it fails
            }
            console.error("Fetch request failed:", errorDetails);
            throw new Error(errorDetails); // Throw an error to be caught by the catch block
        }

        // --- This is the ONLY parsing step needed ---
        // response.json() parses the valid JSON sent by the Python backend
        const optionsData = await response.json(); 
        // optionsData should now be the JavaScript array: [{option: ..., summary: ...}, ...]

        console.log("Successfully received and parsed data:", optionsData); // Log the actual data array

        // --- Use the correctly parsed data ---
        // Optional: Add a check to ensure it's actually an array
        if (Array.isArray(optionsData)) {
            generateLlmButtons(optionsData); // Pass the parsed array directly
        } else {
            console.error("Error: Data received from server is not an array.", optionsData);
            // Handle this error appropriately - maybe show a message or generate empty buttons
            // generateLlmButtons([]); // Example: Call with empty array on error
        }

    } catch (error) {
        // Catch errors from fetch() itself (e.g., network error) or from response.ok check or response.json() parsing
        console.error('Error in getCurrentEvents function:', error);
        // You might want to display an error message to the user here
    } finally {
        // Ensure the loading indicator is always hidden, even if errors occurred
        document.getElementById('loading-indicator').style.display = 'none'; 
    }
}

// --- LLM Interaction ---
async function getLLMResponse(prompt) {
    console.log("Sending LLM Request (Prompt length):", prompt.length);
    try {
        // DO NOT set activeLLMPromptForContext here.
        // 'activeLLMPromptForContext' should already hold the concise, user-facing prompt set *before* this function was called.
        // Helper function to robustly clean and prepare a string for JSON.parse
        function prepareJsonString(str) {
            if (typeof str !== 'string') return ''; 

            // 1. Remove markdown fences and trim
            let cleaned = str.trim().replace(/^```json\s*/i, '').replace(/\s*```$/, '').trim();

            // 2. Remove trailing commas from objects and arrays
            // Regex: /,(?=\s*[}\]])/g matches a comma that is followed by optional whitespace and then a } or ]
            cleaned = cleaned.replace(/,(?=\s*[}\]])/g, '');
            return cleaned;
        }

        // MODIFICATION HERE: Add the 'X-User-ID' header
        const response = await fetch('/llm', {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
                'X-User-ID': currentUserId // <--- ADD THIS LINE!
            },
            body: JSON.stringify({ prompt: prompt }),
        });


        if (!response.ok) { const eT = await response.text(); throw new Error(`LLM HTTP error! status: ${response.status} ${eT}`); }
        const rawData = await response.text();
        console.log("LLM Response Received (Raw):", rawData);

        let optionsData = []; 
        let jsonStringToParse = prepareJsonString(rawData);

        if (!jsonStringToParse) {
            console.warn("LLM returned empty or whitespace-only string after initial clean.");
            return [];
        }

        try {
        
            let parsedJson;
            try {
                 parsedJson = JSON.parse(jsonStringToParse);
            } catch (initialParseError) {
                 // This might happen if rawData itself is a string representing JSON, e.g. "\"[{...}]\""
                // and JSON.parse(rawData) would return the inner string "[{...}]".
                // Or, if prepareJsonString(rawData) still results in invalid JSON.
                console.warn("Initial direct parse failed. Attempting to parse rawData as string-encoded JSON.", initialParseError.message);
                try {
                    // Try parsing rawData as if it's a string literal that needs unescaping first.
                    const stringDecodedJson = JSON.parse(rawData.trim()); // Trim rawData before this parse
                    if (typeof stringDecodedJson === 'string') {
                        // If it was doubly encoded, stringDecodedJson is now the inner JSON string.
                        // Clean and parse this inner string.
                        jsonStringToParse = prepareJsonString(stringDecodedJson);
                        if (!jsonStringToParse) {
                            console.warn("Inner JSON string content after clean was empty.");
                            return [];
                        }
                        console.log("Attempting to parse cleaned inner JSON string:", jsonStringToParse);
                        parsedJson = JSON.parse(jsonStringToParse);
                    } else {
                        // If JSON.parse(rawData.trim()) worked and didn't return a string,
                        // it means rawData was valid JSON to begin with, but the first attempt
                        // with prepareJsonString + parse failed. This is unusual.
                        // We'll use this result but it might indicate other issues.
                        console.warn("Parsed rawData directly, bypassing initial prepareJsonString result.");
                        parsedJson = stringDecodedJson;
                    }
                } catch (secondParseAttemptError) {
                    console.error("Second parse attempt (as string-encoded or direct rawData) also failed.", secondParseAttemptError.message);
                    throw secondParseAttemptError; // Re-throw to trigger the main fallback processingError
                } 
            }


            // This block handles the case where the first successful parse (either direct or via string-decode)
            // itself returned a string that needs to be parsed.

            if (typeof parsedJson === 'string') {
                console.warn("Parse resulted in a string. Content:", JSON.stringify(parsedJson) + ". Attempting to clean and parse this string content.");
                jsonStringToParse = prepareJsonString(parsedJson); 
                console.warn("String content after prepareJsonString for re-parse:", JSON.stringify(jsonStringToParse));
                if (!jsonStringToParse) {
                    console.warn("String content for re-parse was empty after cleaning.");
                    return [];
                }
                parsedJson = JSON.parse(jsonStringToParse);  
            }


            if (Array.isArray(parsedJson)) {
                optionsData = parsedJson;
                // Tag LLM-generated options
                optionsData = parsedJson.map(opt => ({
                    ...opt,
                    isLLMGenerated: true,
                    // Use activeLLMPromptForContext for a more concise, user-facing original prompt
                    originalPrompt: activeLLMPromptForContext, // Concise prompt
                    originatingButtonText: activeOriginatingButtonText // Text of the button that started this
                }));
                console.log("Successfully parsed LLM response as JSON array.");

                const isValidItem = (item) => item && typeof item === 'object' && 'option' in item && 'summary' in item && typeof item.option === 'string' && typeof item.summary === 'string';
                const originalLength = optionsData.length;
                optionsData = optionsData.filter(isValidItem);
                if (optionsData.length !== originalLength) {
                    console.warn(`Filtered out ${originalLength - optionsData.length} invalid items.`);
                }
                return optionsData; // Return valid (potentially filtered) array

            } else {
                console.warn("Final parsed result is not an array. Type:", typeof parsedJson, "Value:", parsedJson);
                throw new Error("Final parsed JSON is not an array."); // Trigger main fallback processingError
            }
        } catch (processingError) { // Catches errors from parsing attempts or validation
            console.error("LLM response processing error:", processingError.message, processingError);
            console.error("Original Raw Data for fallback:", rawData);
            // Fallback: Split text and create basic objects
            // Use prepareJsonString on rawData for fallback cleaning (markdown, trailing commas if any part was parsable)
            const cleanedForFallback = prepareJsonString(rawData);
            let lines = cleanedForFallback
                .split("\n")
                .map(line => line.trim())
                .map(line => line.replace(/^\s*[-\*\d]+\.?\s*/, '')) // Remove list markers
                .filter(line => line && !line.startsWith("[") && !line.startsWith("]") && !line.startsWith("{") && !line.startsWith("}")); // Filter artifacts

             // If after cleaning, lines is empty but cleanedForFallback was not, it might be a single line JSON
            if (lines.length === 0 && cleanedForFallback.length > 0) {
                lines = [cleanedForFallback]; // Treat the whole cleaned string as one line
            }

            console.warn("Falling back to basic text splitting. Lines found:", lines.length);
            
            optionsData = lines.map(optionText => ({
                option: optionText, summary: optionText, isLLMGenerated: true,
                originalPrompt: activeLLMPromptForContext, // Use concise context
                originatingButtonText: activeOriginatingButtonText
            }));
            
            // Enhanced fallback: If split results in one big JSON-like string, try to extract "option" values
            if (optionsData.length === 1 && optionsData[0].option.trim().startsWith('[') && optionsData[0].option.trim().endsWith(']')) {
                console.warn("Fallback resulted in a single button with JSON-like content. Attempting to extract 'option' values using regex.");
                const extractedOptions = [];
                const optionRegex = /"option"\s*:\s*"((?:\\.|[^"\\])*)"/g; // Matches "option": "value" and handles escaped quotes in value
                let match;
                while ((match = optionRegex.exec(optionsData[0].option)) !== null) {
                    const optionValue = match[1].replace(/\\"/g, '"').replace(/\\\\/g, '\\'); // Unescape quotes and backslashes
                    extractedOptions.push({ 
                        option: optionValue, summary: optionValue, isLLMGenerated: true,
                        originalPrompt: activeLLMPromptForContext, // Use concise context
                        originatingButtonText: activeOriginatingButtonText
                    });
                }
                if (extractedOptions.length > 0) {
                    console.log("Extracted options from fallback content:", extractedOptions);
                    optionsData = extractedOptions;
                } else {
                    console.warn("Could not extract individual 'option' values from fallback content via regex.");
                }
            }
            console.log("getLLMResponse returning (fallback):", optionsData);
            return optionsData;
        }

    } catch (error) {
        // activeLLMPromptForContext is not cleared here, as it might be needed if retrying or for subsequent UI state. It's cleared elsewhere upon successful action or navigation.
        console.error("Error fetching or processing LLM Response:", error);
        return []; // Return empty array on fetch error or other exceptions
    }
}


// --- Speech Recognition (Keyword and Question) ---
let recognition = null;
let isSettingUpRecognition = false;
let listeningForQuestion = false; // This flag is crucial

function setupSpeechRecognition() {
    if (isSettingUpRecognition || recognition) { return; }
    isSettingUpRecognition = true;
    console.log("Setting up Keyword speech recognition...");
    const SpeechRecognitionAPI = window.SpeechRecognition || window.webkitSpeechRecognition;
    if (!SpeechRecognitionAPI) {
        console.error("Speech Recognition API not supported."); isSettingUpRecognition = false; return;
    }
    recognition = new SpeechRecognitionAPI();
    recognition.continuous = true;
    recognition.interimResults = false;
    console.log("Keyword Recognition object created:", recognition);

    recognition.onerror = function (event) {
        console.error("Keyword Speech recognition error:", event.error, event.message);
        if (['no-speech', 'audio-capture', 'network'].includes(event.error) && !listeningForQuestion) { // Only restart if not trying to listen for a question
             console.log("Keyword recognition error, attempting restart...");
             setTimeout(() => { recognition = null; isSettingUpRecognition = false; setupSpeechRecognition(); }, 1000);
        } else { isSettingUpRecognition = false; recognition = null; }
    };

    recognition.onresult = async (event) => {
        const transcript = event.results[event.results.length - 1][0].transcript.toLowerCase().trim();
        console.log('Keyword check - Speech recognized:', transcript);
        if (listeningForQuestion) { console.log("Ignoring keyword, currently listening for question."); return; }

        const interjectionToUse = wakeWordInterjection || "hey";
        const nameToUse = wakeWordName || "brady";
        const phraseWithSpace = `${interjectionToUse} ${nameToUse}`;
        const phraseWithComma = `${interjectionToUse}, ${nameToUse}`;
        const phraseWithCommaNoSpace = `${interjectionToUse},${nameToUse}`;

        console.log(`Checking for: "${phraseWithSpace}" OR "${phraseWithComma}" OR "${phraseWithCommaNoSpace}"`);

        if (transcript.includes(phraseWithSpace) || transcript.includes(phraseWithComma) || transcript.includes(phraseWithCommaNoSpace)) {
            console.log(`Keyword detected! ("${transcript}")`);
            stopAuditoryScanning();
            if (recognition) {
                console.log("Stopping keyword recognition...");
                try { recognition.stop(); } catch(e) { console.warn("Error stopping keyword recognition:", e); }
                recognition.onresult = null; recognition.onerror = null; recognition.onend = null; recognition = null;
                console.log("Stopped and cleared keyword recognition instance.");
            }
             isSettingUpRecognition = false;

            // *** HIGHLIGHT QUESTION TEXTAREA ***
            const questionTextarea = document.getElementById(QUESTION_TEXTAREA_ID);
            if (questionTextarea) {
                questionTextarea.classList.add(LISTENING_HIGHLIGHT_CLASS);
                questionTextarea.placeholder = "Listening for your question..."; // Update placeholder
            }

            const announcement = 'Listening for your question...';
            console.log("Calling announce for question prompt...");
            try {
                await announce(announcement, "system", false);
                console.log("Announce finished. Setting up question recognition.");
                setupQuestionRecognition(); // This will set listeningForQuestion = true
            } catch (announceError) {
                 console.error("Error during announcement:", announceError);
                 if (questionTextarea) questionTextarea.classList.remove(LISTENING_HIGHLIGHT_CLASS); // Remove highlight on error
                 setupSpeechRecognition(); // Restart keyword spotting
            }
        }
    };

    recognition.onend = () => {
        console.log("Keyword Recognition ended.");
        if (!listeningForQuestion && !isSettingUpRecognition && recognition) {
             console.log("Keyword recognition ended unexpectedly, restarting.");
             recognition = null; setTimeout(setupSpeechRecognition, 500);
        } else {
             console.log("Keyword recognition ended normally or was already being reset/stopped.");
             isSettingUpRecognition = false;
        }
    };

    try { recognition.start(); console.log("Keyword recognition started."); isSettingUpRecognition = false; }
    catch (e) { console.error("Error starting keyword recognition:", e); isSettingUpRecognition = false; recognition = null; }
}

function setupQuestionRecognition() {
    console.log("Attempting to set up question recognition...");
    const SpeechRecognitionAPI = window.SpeechRecognition || window.webkitSpeechRecognition;
    if (!SpeechRecognitionAPI) { console.error("Speech Recognition API not supported."); announce("Sorry, I can't use speech recognition.", "system", false); return; }

    let questionRecognitionInstance = new SpeechRecognitionAPI(); // Use local instance
    questionRecognitionInstance.lang = 'en-US';
    questionRecognitionInstance.continuous = false;
    questionRecognitionInstance.interimResults = true;
    questionRecognitionInstance.maxAlternatives = 1;

    let finalTranscript = ''; let listeningTimeout; let hasProcessedResult = false; let isRestartingKeyword = false;
    const questionTextarea = document.getElementById(QUESTION_TEXTAREA_ID);

    console.log("Question Recognition Config:", { continuous: false, interimResults: true, lang: 'en-US', maxAlternatives: 1 });

    questionRecognitionInstance.onstart = () => {
        console.log("Question Recognition: Listening started...");
        finalTranscript = ''; hasProcessedResult = false;
        if (questionTextarea) {
            questionTextarea.placeholder = "Listening..."; // Ensure placeholder is set
            questionTextarea.value = "";
            questionTextarea.classList.add(LISTENING_HIGHLIGHT_CLASS); // Ensure highlight is on
        }
        listeningForQuestion = true; // Set global state
        clearTimeout(listeningTimeout);
        listeningTimeout = setTimeout(() => {
             if (listeningForQuestion && !finalTranscript && !hasProcessedResult) {
                 console.log("Question Timeout: No speech detected."); announce("I didn't hear anything. Try again?", "system", false);
                 try { questionRecognitionInstance.stop(); } catch(e){}
             }
        }, 10000);
    };

    questionRecognitionInstance.onresult = async (event) => {
        console.log("Question onresult."); if (hasProcessedResult) return; clearTimeout(listeningTimeout);
        let interimTranscript = '';
        for (let i = event.resultIndex; i < event.results.length; ++i) {
            const transcriptPart = event.results[i][0].transcript;
            if (event.results[i].isFinal) { finalTranscript += transcriptPart; } else { interimTranscript += transcriptPart; }
        }
        const displayTranscript = finalTranscript || interimTranscript;
        if (questionTextarea) questionTextarea.value = displayTranscript.trim();

        const isFinishedUtterance = event.results[event.results.length - 1].isFinal;

        if (isFinishedUtterance && finalTranscript.trim()) {
            hasProcessedResult = true; console.log("Final Question:", finalTranscript.trim().toLowerCase());
            listeningForQuestion = false; // Set state BEFORE async

            // *** REMOVE HIGHLIGHT & SHOW LOADING ***
            if (questionTextarea) questionTextarea.classList.remove(LISTENING_HIGHLIGHT_CLASS);
            document.getElementById('loading-indicator').style.display = 'flex';

            try {
                announce("Okay, processing: " + finalTranscript.trim() + ". Give me a moment.", "system", false);
                currentQuestion = finalTranscript.trim().toLowerCase();

                const summaryInstruction = SummaryOff
                ? 'The "summary" key should contain the exact same FULL text as the "option" key.'
                : 'If the generated option is more than 5 words, the "summary" key should be a 3-5 word abbreviation of each option, including the exact key words from the option. If the option is 5 words or less, the "summary" key should contain the exact same FULL text as the "option" key.';
                activeLLMPromptForContext = currentQuestion; // Set context to just the user's question
                activeOriginatingButtonText = "Voice Input"; // Mark as voice-initiated

                const promptForLLM = `
                    Provide up to "${LLMOptions}" short, single-phrase options related to: "${currentQuestion}".
                    Do not include any introductory or concluding text.
                    Format your response as a JSON list where each item has "option" and "summary" keys.
                    The "option" key should contain the FULL option text. If the option contains a question and answer, like a joke, the option contain the question and the answer.
                    ${summaryInstruction}
                    Example: [{"option": "...", "summary": "..."}]
                `;
                document.getElementById('loading-indicator').style.display = 'flex';
                const options = await getLLMResponse(promptForLLM);
                if (Array.isArray(options) && (options.length === 0 || options.every(o => typeof o === 'object' && o !== null && 'option' in o && 'summary' in o))) {
                    querytype = "question"; generateLlmButtons(options);
                } else {
                    console.error("LLM response invalid:", options); announce("Unexpected response.", "system", false);
                    isRestartingKeyword = true; setupSpeechRecognition();
                }
            } catch (error) {
                console.error('Error processing question:', error); announce("Error processing question.", "system", false);
                isRestartingKeyword = true; setupSpeechRecognition();
            } finally {
                //document.getElementById('loading-indicator').style.display = 'none';
                document.getElementById('loading-indicator').style.display = 'none'; // Ensure indicator is hidden
                if (questionTextarea) questionTextarea.placeholder = "Ask a question..."; 
                console.log("LLM processing finished for question.");
            }
        } else if (!isFinishedUtterance) { console.log("Waiting for final result..."); }
        else { console.log("Final utterance empty."); listeningForQuestion = false; if (questionTextarea) questionTextarea.classList.remove(LISTENING_HIGHLIGHT_CLASS); }
    };

    questionRecognitionInstance.onerror = (event) => {
        clearTimeout(listeningTimeout); if (hasProcessedResult) return;
        console.error("Question Error:", event.error, event.message);
        let errorMessage = "Speech recognition error."; let attemptRetry = false;
        if (event.error === 'no-speech') {
            errorMessage = "Didn't hear anything. Try again?";
            if (!questionRecognitionInstance.hasRetried) { attemptRetry = true; errorMessage += " Retrying..."; questionRecognitionInstance.hasRetried = true; } // Use instance flag
            else { console.log("Already retried."); }
        } else if (event.error === 'not-allowed' || event.error === 'service-not-allowed') { errorMessage = "Mic access denied."; }
        else if (event.error === 'audio-capture') { errorMessage = "Mic problem."; }
        else if (event.error === 'network') { errorMessage = "Network error."; }
        else if (event.error === 'aborted') { errorMessage = ""; }

        if (errorMessage) { announce(errorMessage, "system", false); }
        document.getElementById('loading-indicator').style.display = 'none';
        if (questionTextarea) {
            questionTextarea.placeholder = "Ask a question...";
            questionTextarea.classList.remove(LISTENING_HIGHLIGHT_CLASS); // Remove highlight on error
        }
        listeningForQuestion = false;
        try { questionRecognitionInstance.stop(); } catch(e) {}

        if (attemptRetry) {
            console.log("Attempting retry...");
            setTimeout(() => {
                 try { finalTranscript = ''; listeningForQuestion = true; hasProcessedResult = false; questionRecognitionInstance.start(); }
                 catch (e) { console.error("Retry start error:", e); announce("Retry failed.", "system", false); listeningForQuestion = false; isRestartingKeyword = true; setupSpeechRecognition(); }
            }, 500);
        } else { 
            console.log("Not retrying. Restarting keyword listener.");
            isRestartingKeyword = true;
            setupSpeechRecognition();
            if (document.querySelectorAll('#gridContainer button:not([style*="display: none"])').length > 0) {
                console.log("Error in question rec (not retrying), restarting scanning for existing buttons.");
                startAuditoryScanning();
            }
        }
    };

    questionRecognitionInstance.onend = () => {
        clearTimeout(listeningTimeout); console.log("Question Recognition ended.");
        const wasRetried = questionRecognitionInstance?.hasRetried; const stillListening = listeningForQuestion; // Capture state before reset
        if (listeningForQuestion) { listeningForQuestion = false; console.log("Reset listening flag in onend."); }

        if (questionTextarea) {
            questionTextarea.classList.remove(LISTENING_HIGHLIGHT_CLASS); // Ensure highlight is removed
            questionTextarea.placeholder = "Ask a question...";
        }
        // document.getElementById('loading-indicator').style.display = 'none'; // Moved to onresult's finally block

        if (stillListening && !hasProcessedResult && !wasRetried) { console.log("Ended without result/retry."); announce("Didn't catch that. Try again?", "system", false); }

        if (!hasProcessedResult && !isRestartingKeyword) {
            console.log("Restarting keyword listener from onend.");
            setupSpeechRecognition();
            // If ending without result and falling back to keyword spotting, attempt to restart scanning.
            if (document.querySelectorAll('#gridContainer button:not([style*="display: none"])').length > 0) {
                console.log("Question rec ended (no result), restarting scanning for existing buttons.");
                startAuditoryScanning();
            }
        } else { console.log("Not restarting keyword listener from onend (processed, retrying, or handled by error)."); }

        questionRecognitionInstance = null; console.log("Question instance cleaned up.");
    };

    questionRecognitionInstance.onnomatch = () => { console.warn("Question No match."); };
    questionRecognitionInstance.onspeechend = () => {
        console.log("Question Speech ended."); clearTimeout(listeningTimeout);
        listeningTimeout = setTimeout(() => {
            if (listeningForQuestion && !hasProcessedResult) {
                console.warn("Timeout after speech end."); announce("Didn't get a final result.", "system", false);
                try { questionRecognitionInstance.stop(); } catch(e){}
            }
        }, 5000);
    };
    questionRecognitionInstance.onsoundend = () => { console.log("Question Sound ended."); };

    setTimeout(() => {
        try { console.log("Calling start() for question recognition..."); questionRecognitionInstance.start(); }
        catch (e) { console.error("Start error:", e); announce("Couldn't start listening.", "system", false); listeningForQuestion = false; clearTimeout(listeningTimeout); isRestartingKeyword = true; setupSpeechRecognition(); }
    }, 150);
}


// --- Core Audio Playback Function (Centralized audio processing) ---
// This function is called by `processAnnouncementQueue` to play synthesized audio.
async function playAudioToDevice(audioDataBuffer, sampleRate, announcementType) { // announcementType needed to determine target speaker
    console.log(`playAudioToDevice: Starting playback for type "${announcementType}"`);

    // Get speaker IDs directly here, as this is the actual playback point.
    const personalSpeakerId = localStorage.getItem('bravoPersonalSpeakerId') || 'default';
    const systemSpeakerId = localStorage.getItem('bravoSystemSpeakerId') || 'default';
    
    let targetOutputDeviceId;
    if (announcementType === 'personal') {
        targetOutputDeviceId = personalSpeakerId;
    } else if (announcementType === 'system') {
        targetOutputDeviceId = systemSpeakerId;
    } else {
        targetOutputDeviceId = 'default';
    }
    console.log(`playAudioToDevice: Final targetOutputDeviceId: "${targetOutputDeviceId}"`);

    if (!audioDataBuffer) {
        console.error('playAudioToDevice: No audio data buffer provided.');
        throw new Error('No audio data buffer provided.');
    }

    let audioContext;
    let source;

    try {
        audioContext = new (window.AudioContext || window.webkitAudioContext)();
        if (audioContext.state === 'suspended') {
            console.log("playAudioToDevice: AudioContext is suspended, attempting to resume.");
            // We resume here; the tryResumeAudioContext() will provide the gesture.
            audioContext.resume().catch(err => {
                console.warn("playAudioToDevice: .resume() failed, probably no user gesture yet:", err);
            });
        }

        if (typeof audioContext.setSinkId === 'function' && targetOutputDeviceId && targetOutputDeviceId !== 'default') {
            console.log(`playAudioToDevice: Attempting to call audioContext.setSinkId to device (ID: ${targetOutputDeviceId})`);
            await audioContext.setSinkId(targetOutputDeviceId);
            console.log(`playAudioToDevice: setSinkId call FINISHED for device ${targetOutputDeviceId}`);
        } else {
            console.warn(`playAudioToDevice: Not performing explicit routing. Audio will play to browser's default speaker.`);
        }

        const audioBuffer = await audioContext.decodeAudioData(audioDataBuffer);
        console.log("playAudioToDevice: Audio data decoded. Buffer duration:", audioBuffer.duration);

        source = audioContext.createBufferSource();
        source.buffer = audioBuffer;
        source.connect(audioContext.destination);
        source.start(0);
        console.log("playAudioToDevice: Audio source started.");

        return new Promise((resolve) => {
            source.onended = () => {
                console.log("playAudioToDevice: Audio playback ended.");
                audioContext.close(); // Important to release resources
                resolve();
            };
        }).catch(err => {
            console.error("playAudioToDevice: Error during audio playback promise:", err);
            if (audioContext && audioContext.state !== 'closed') audioContext.close();
            throw err;
        });

    } catch (error) {
        console.error('playAudioToDevice: Fatal Error during setup or playback:', error);
        if (audioContext && audioContext.state !== 'closed') audioContext.close();
        throw error;
    }
}

// --- Announcement Queue Processor ---
// This function manages playing announcements from the queue sequentially.
async function processAnnouncementQueue() {
    if (isAnnouncingNow || announcementQueue.length === 0) {
        return; // Already playing or nothing to play.
    }

    isAnnouncingNow = true;
    // Get and remove the first item from the queue, containing actual announcement details and its original promise handlers.
    const { textToAnnounce, announcementType, recordHistory, resolve, reject } = announcementQueue.shift(); 

    console.log(`ANNOUNCE QUEUE: Playing "${textToAnnounce.substring(0, 30)}..." (Type: ${announcementType})`);

    try {
        // Fetch audio data from your server
        const response = await fetch(`${SERVER_URL}/play-audio`, {
            method: 'POST',
            headers: {  
                'Content-Type': 'application/json',
                'X-User-ID': currentUserId // Use currentUserId as per your file
            },
            body: JSON.stringify({ text: textToAnnounce, routing_target: announcementType }), 
        });

        if (!response.ok) {
            const errorBody = await response.json().catch(() => response.text());
            throw new Error(`Failed to synthesize audio: ${response.status} - ${JSON.stringify(errorBody)}`);
        }

        const jsonResponse = await response.json();
        const audioData = jsonResponse.audio_data;
        const sampleRate = jsonResponse.sample_rate;

        if (!audioData) {
            throw new Error("No audio data received from server.");
        }

        // Convert Base64 to ArrayBuffer and play
        const audioDataArrayBuffer = base64ToArrayBuffer(audioData);
        await playAudioToDevice(audioDataArrayBuffer, sampleRate, announcementType); // Direct call to new helper.

        // Record history (as per your original announce)
        if (recordHistory) {
            const speechHistory = document.getElementById('speech-history');
            if (speechHistory) {
                let history = (localStorage.getItem(SPEECH_HISTORY_LOCAL_STORAGE_KEY(currentUserId)) || '').split('\n').filter(Boolean);
                history.unshift(textToAnnounce);
                if (history.length > 20) { history = history.slice(0, 20); }
                speechHistory.value = history.join('\n');
                localStorage.setItem(SPEECH_HISTORY_LOCAL_STORAGE_KEY(currentUserId), speechHistory.value);
            } else {
                console.warn("Speech history textarea not found for recording.");
            }
        }
        
        // Resolve the original promise that was returned by the `announce` function call.
        resolve(); 

    } catch (error) {
        console.error('ANNOUNCE QUEUE: Error during announcement playback:', error);
        reject(error); // Reject the original promise.
    } finally {
        isAnnouncingNow = false; // Allow the next item in queue to play.
        // Recursively call to process the next item if available.
        if (announcementQueue.length > 0) {
            processAnnouncementQueue();
        }
    }
}

// --- Announce Function (MODIFIED to use the queue) ---
// This function will now queue up messages for sequential playback.
async function announce(textToAnnounce, announcementType = "system", recordHistory = true) {
    console.log(`ANNOUNCE: QUEUING "${textToAnnounce.substring(0, 30)}..." (Type: ${announcementType})`);
    
    // Create and return a new Promise, whose resolve/reject functions are stored in the queue.
    return new Promise((resolve, reject) => {
        announcementQueue.push({
            textToAnnounce,
            announcementType,
            recordHistory,
            resolve, // Store the resolve function of this promise
            reject   // Store the reject function of this promise
        });

        // Trigger the queue processing. It will only start playing if not already playing.
        processAnnouncementQueue();
    });
}


// --- Global AudioContext Resume Helper ---
// This function tries to resume the AudioContext on first user gesture.
function tryResumeAudioContext() {
    if (window.AudioContext && !audioContextResumeAttempted) {
        const audioContext = new (window.AudioContext || window.webkitAudioContext)();
        if (audioContext.state === 'suspended') {
            audioContext.resume().then(() => {
                console.log('AudioContext resumed via user gesture.');
            }).catch(e => {
                console.warn('Failed to auto-resume AudioContext on initial gesture:', e);
            });
        }
        audioContextResumeAttempted = true; // Ensure this only runs once per page load
    }
}




// --- Auditory Scanning ---
function startAuditoryScanning() {
    stopAuditoryScanning();
    if (ScanningOff) { console.log("Auditory scanning is off."); return; }
    console.log("Starting auditory scanning...");
    const buttons = Array.from(document.querySelectorAll('#gridContainer button:not([style*="display: none"])'));
    if (buttons.length === 0) { console.log("No visible buttons found."); currentlyScannedButton = null; return; }
    currentButtonIndex = -1;

    const scanStep = () => {
        if (currentlyScannedButton) { currentlyScannedButton.classList.remove('scanning'); }
        currentButtonIndex++;
        if (currentButtonIndex >= buttons.length) { currentButtonIndex = 0; }
        if (buttons[currentButtonIndex]) {
            currentlyScannedButton = buttons[currentButtonIndex];
            speakAndHighlight(currentlyScannedButton);
        } else { console.warn("Button not found at index:", currentButtonIndex); currentButtonIndex = -1; }
    };
    console.log(`Scan delay set to: ${defaultDelay}ms`);
    scanStep(); // Perform first scan immediately
    scanningInterval = setInterval(scanStep, defaultDelay);
}

async function speakAndHighlight(button) {
    document.querySelectorAll('#gridContainer button.scanning').forEach(btn => { btn.classList.remove('scanning'); });
    button.classList.add('scanning');
    try {
        const textToSpeak = button.textContent;
        const utterance = new SpeechSynthesisUtterance(textToSpeak);
        window.speechSynthesis.cancel();
        window.speechSynthesis.speak(utterance);
    } catch (e) { console.error("Speech synthesis error:", e); }
}

function stopAuditoryScanning() {
    console.log("Stopping auditory scanning.");
    clearInterval(scanningInterval); scanningInterval = null;
    if (currentlyScannedButton) { currentlyScannedButton.classList.remove('scanning'); currentlyScannedButton = null; }
    currentButtonIndex = -1; window.speechSynthesis.cancel();
}

// --- LLM Button Generation ---
function generateLlmButtons(options) {
    options = Array.isArray(options) ? options : [];
    stopAuditoryScanning();
    const gridContainer = document.getElementById('gridContainer');
    if (!gridContainer) { console.error("gridContainer not found!"); return; }
    gridContainer.innerHTML = '';
    currentOptions = options;
    let isAnnouncing = false;
    console.log("Generating buttons for options:", options);

     // --- Define Tailwind classes ---
     const baseButtonClasses = [ 'grid-button-base', 'w-full', 'h-auto', 'text-white', 'font-semibold', 'text-sm', 'sm:text-base', 'p-3', 'rounded-lg', 'shadow-md', 'border-2', 'transition', 'duration-150', 'ease-in-out', 'transform', 'hover:-translate-y-0.5', 'flex', 'items-center', 'justify-center', 'text-center', 'cursor-pointer', 'focus:outline-none', 'focus:ring-2', 'focus:ring-offset-2', 'mb-3' ];
     const llmButtonColors = [ 'bg-teal-600', 'border-teal-800', 'hover:bg-teal-700', 'hover:border-teal-900', 'focus:ring-teal-500' ];
     const specialButtonColors = [ 'bg-gray-600', 'border-gray-800', 'hover:bg-gray-700', 'hover:border-gray-900', 'focus:ring-gray-500' ];
     const askAgainButtonColors = [ 'bg-yellow-500', 'border-yellow-700', 'hover:bg-yellow-600', 'hover:border-yellow-800', 'text-black', 'focus:ring-yellow-400' ];
     const goBackButtonColors = [ 'bg-gray-200', 'border-gray-400', 'hover:bg-gray-300', 'hover:border-gray-500', 'text-black', 'focus:ring-gray-300' ];

    // --- Generate Buttons for LLM Options ---
    options.forEach(optionData => {
        if (!optionData || typeof optionData.summary !== 'string' || typeof optionData.option !== 'string') { console.warn("Skipping invalid option data:", optionData); return; }
        const button = document.createElement('button');
        button.textContent = optionData.summary;
        button.dataset.option = optionData.option;
        button.dataset.speechPhrase = optionData.option;
        button.className = [...baseButtonClasses, ...llmButtonColors].join(' ');


        // Pass the full optionData object, which now includes isLLMGenerated and originalPrompt
        button.addEventListener('click', debounce(async () => {
            if (isAnnouncing) { console.log("Announcement in progress..."); return; }
            isAnnouncing = true;
            stopAuditoryScanning(); // Stop scanning when an option is chosen
            console.log("LLM Button Click. Announcing:", optionData.option); // Log the full option text

            // --- Log LLM Button Click for Audit ---
            const clickTimestamp = new Date().toISOString();
            const pageInfo = getCurrentPageInfo();
            const logData = {
                timestamp: clickTimestamp,
                page_name: pageInfo.name,
                page_context_prompt: optionData.originalPrompt, // From tagged optionData
                button_text: optionData.option,
                button_summary: optionData.summary,
                is_llm_generated: optionData.isLLMGenerated, // Should be true
                originating_button_text: optionData.originatingButtonText // NEW: Add originating button text
            };
            console.log("Logging LLM button click data:", logData);
            try {
                const auditResponse = await fetch('/api/audit/log-button-click', {
                    method: 'POST',
                    headers: {
        'Content-Type': 'application/json',
        'X-User-ID': currentUserId // <-- ADD THIS LINE
      },
                    body: JSON.stringify(logData)
                });
                if (!auditResponse.ok) console.error("Failed to log LLM button click:", auditResponse.status, await auditResponse.text());
                else console.log("LLM button click logged successfully:", logData);
            } catch (auditError) {
                console.error("Error sending LLM button click log:", auditError);
            }
            // --- End Audit Logging ---
            try {
                // Announce the selected option (using the full option text for clarity)
                await announce(optionData.option, "system"); // Use optionData.option directly
                console.log("Announcement finished for:", button.dataset.option);

                // Clear the question display after announcement
                activeLLMPromptForContext = null; // Clear context after selection
                const questionDisplay = document.getElementById('question-display');
                if (questionDisplay) { questionDisplay.value = ''; }

                // Reload the page to go back to the initial state
                // Consider if this is always the desired behavior
                window.location.reload(true);

            } catch (error) {
                 console.error("Error during announcement or reload:", error);
                 // Optionally restart scanning here if announce fails
                 startAuditoryScanning();
            } finally {
                isAnnouncing = false; // Reset flag  
            }
        }, clickDebounceDelay)); // Apply debounce
        gridContainer.appendChild(button);
    });

    // --- Generate Special Buttons ---
    // (Ensure these also have the base class and appropriate color classes)
    const somethingElseButton = document.createElement('button');
    somethingElseButton.textContent = 'Something Else';
    somethingElseButton.className = [...baseButtonClasses, ...specialButtonColors].join(' ');
    somethingElseButton.addEventListener('click', async () => {
        stopAuditoryScanning(); // Stop scanning before fetching new options
        console.log("Something Else button clicked. Query Type:", querytype, "Current Question context:", currentQuestion);

       try { // Wrap main logic
            // --- Logic based on query type ---
            if (querytype === "currentevents") {
                // For "Something Else" in current events, the activeOriginatingButtonText
                // should still be the category button that initiated it.
                console.log("Getting next set of current events for type:", eventtype);
                await getCurrentEvents(eventtype); // This calls generateLlmButtons, which starts scanning
            } else if (querytype === "question" || querytype === "options") {
                document.getElementById('loading-indicator').style.display = 'flex';
                try {
                    const excludedOptionsText = currentOptions
                        .map(opt => opt.option)
                        .filter(text => typeof text === 'string' && text.trim() !== '')
                        .join("; ");
                    console.log("Excluding options:", excludedOptionsText);

                    const summaryInstruction = SummaryOff
                        ? 'The "summary" key should contain the exact same FULL text as the "option" key.'
                        : 'If the generated option is more than 5 words, the "summary" key should be a 3-5 word abbreviation of each option, including the exact key words from the option. If the option is 5 words or less, the "summary" key should contain the exact same FULL text as the "option" key.';
                        // Set activeLLMPromptForContext to the original concise question before calling getLLMResponse
                        activeLLMPromptForContext = currentQuestion;
                        // activeOriginatingButtonText should still be set from the initial question or button click
                        // that generated the current set of options.
                    const prompt = `
                        For the question "${currentQuestion}", provide new options.
                        IMPORTANTLY, exclude the following options if possible: "${excludedOptionsText}".
                        Return ONLY a numbered list of the new options. Do not include any introductory or concluding text.
                        Format your response as a JSON list where each item has "option" and "summary" keys.
                        ${summaryInstruction}
                        The "option" key should contain the FULL option text. If the option contains a question and answer, like a joke, the option contain the question and the answer.
                        Example: [{"option": "...", "summary": "..."}]
                    `;
                    console.log("Sending prompt for 'Something Else' options:", prompt);

                    const response = await getLLMResponse(prompt); // Expects an array

                    if (Array.isArray(response)) {
                        if (response.length > 0) {
                            generateLlmButtons(response); // This will restart scanning
                        } else {
                            console.warn("LLM did not return any new options after exclusion (array response).");
                            announce("Sorry, I couldn't find any other options for that.", "system", false);
                        }
                    } else if (typeof response === 'string' && response.trim() !== '') { // Fallback for older string response
                        console.warn("Received string response from getLLMResponse for 'Something Else', expected array. Processing as string.");
                        const newOptions = response.split("\n").map(option => option.replace(/^\s*\d+[\.\)]?\s*|\s*\*+\s*|["']/g, '').trim()).filter(option => option !== "");
                        if (newOptions.length > 0) {
                            const newOptionsObjects = newOptions.map(optText => ({ summary: optText, option: optText }));
                            generateLlmButtons(newOptionsObjects); // This will restart scanning
                        } else {
                            console.warn("LLM did not return any new options after exclusion (string response).");
                            announce("Sorry, I couldn't find any other options for that.", "system", false);
                        }
                    } else {
                        console.error("Unexpected or empty response type from getLLMResponse for 'Something Else':", response);
                        announce("Sorry, I received an unexpected response for more options.", "system", false);
                    }
                    } catch (error) {
                    console.error('Error getting new LLM options for "Something Else":', error);
                    announce("Sorry, an error occurred while getting more options.", "system", false);
                } finally {
                    document.getElementById('loading-indicator').style.display = 'none';
                }
                } else {
                console.warn("Something Else clicked with unknown querytype:", querytype);
                announce("Sorry, I'm not sure what to do for 'Something Else' here.", "system", false);
            }
            } finally {
            // This 'finally' ensures that scanning is attempted to be restarted
            // if it wasn't already started by generateLlmButtons (e.g., due to error or no new options).
            if (!scanningInterval) { // Check if scanning is not already active
                console.log("Attempting to restart scanning in 'Something Else' finally block.");
                // Restore activeLLMPromptForContext if needed for scanning, though it's usually for the next LLM call
                // activeLLMPromptForContext = currentQuestion; // Or a specific "something else" context
                startAuditoryScanning();
            }
        }
    });


    
    gridContainer.appendChild(somethingElseButton);

    if (querytype === "question") {
        const askAgainButton = document.createElement('button');
        askAgainButton.textContent = 'Please ask me again';
        askAgainButton.id = 'askAgainButton';
        askAgainButton.className = [...baseButtonClasses, ...askAgainButtonColors].join(' ');
        askAgainButton.addEventListener('click', () => {
            stopAuditoryScanning();
            activeOriginatingButtonText = null; // Reset, as a new question will be asked
            activeLLMPromptForContext = null;
            announce('Okay, please ask your question again after the tone.', "system", false)
                .then(() => { activeLLMPromptForContext = "User chose to ask question again."; })
                .then(() => {
                    // Reset state and start question recognition again
                    listeningForQuestion = false; // Ensure state allows starting new recognition
                    // No need to stop recognition instance here, setupQuestionRecognition creates a new one
                    setTimeout(() => {
                        setupQuestionRecognition(); // Start listening for the question
                    }, 100); // Short delay after announcement
                })
                .catch(err => {
                    console.error("Error announcing 'ask again':", err);
                    // If announce fails, revert to keyword spotting and scan existing buttons
                    setupSpeechRecognition();
                    activeLLMPromptForContext = null; // Clear context
                    if (document.querySelectorAll('#gridContainer button:not([style*="display: none"])').length > 0) {
                        startAuditoryScanning();
                    }
                });
        });
        gridContainer.appendChild(askAgainButton);
    }

    const goBackButton = document.createElement('button');
    goBackButton.textContent = 'Go Back';
    goBackButton.className = [...baseButtonClasses, ...goBackButtonColors].join(' ');
    goBackButton.addEventListener('click', () => {
        activeOriginatingButtonText = null; // Reset on navigation
        activeLLMPromptForContext = null; // Clear context on navigation
        window.location.reload(true);
    })
    gridContainer.appendChild(goBackButton);


    // --- Start Auditory Scanning ---
    if (gridContainer.childElementCount > 0) {
         console.log("Starting auditory scanning for generated LLM/special buttons.");
        // activeLLMPromptForContext is already set by the function that called generateLlmButtons
         startAuditoryScanning();
    } else { console.log("No buttons generated, not starting scanning."); }
}

// --- Input Handling --- ADDED/VERIFIED ---

/**
 * Sets up the keyboard listener for the Spacebar.
 */
function setupKeyboardListener() {
    document.addEventListener('keydown', (event) => {
        if (event.code === 'Space' && !isLLMProcessing && !listeningForQuestion && currentlyScannedButton) {
            event.preventDefault();
            const buttonToActivate = currentlyScannedButton; // Capture the button reference
            console.log("Spacebar pressed, activating button:", buttonToActivate.textContent);
            buttonToActivate.click();
            buttonToActivate.classList.add('active');
            // Use the captured reference in the timeout as well
            setTimeout(() => buttonToActivate?.classList.remove('active'), 150);
        }
    });
    console.log("Keyboard listener (Spacebar) set up.");
}

/**
 * Sets up listeners for gamepad connection/disconnection and starts polling.
 */
function setupGamepadListeners() {
    window.addEventListener("gamepadconnected", (event) => {
        console.log("Gamepad connected:", event.gamepad.index, event.gamepad.id);
        if (gamepadIndex === null) { gamepadIndex = event.gamepad.index; startGamepadPolling(); }
    });
    window.addEventListener("gamepaddisconnected", (event) => {
        console.log("Gamepad disconnected:", event.gamepad.index, event.gamepad.id);
        if (gamepadIndex === event.gamepad.index) { gamepadIndex = null; stopGamepadPolling(); }
    });
    console.log("Gamepad connection listeners set up.");
     const gamepads = navigator.getGamepads ? navigator.getGamepads() : [];
     for (let i = 0; i < gamepads.length; i++) {
         if (gamepads[i]) {
             console.log("Gamepad already connected at index:", i);
             if (gamepadIndex === null) { gamepadIndex = i; startGamepadPolling(); }
             break;
         }
     }
}

/**
 * Starts the gamepad polling loop using requestAnimationFrame.
 */
function startGamepadPolling() {
    if (gamepadPollInterval !== null) return;
    console.log("Starting gamepad polling for index:", gamepadIndex);
    let lastButtonState = false;

    function pollGamepads() {
        if (gamepadIndex === null) { stopGamepadPolling(); return; }
        const gp = navigator.getGamepads()[gamepadIndex];
        if (!gp) { gamepadPollInterval = requestAnimationFrame(pollGamepads); return; } // Keep polling if gp not ready

        const currentButtonState = gp.buttons[0] && gp.buttons[0].pressed;
        if (currentButtonState && !lastButtonState) {
             const now = Date.now();
             if (now - lastGamepadInputTime > 300) { // Rate limit
                if (!isLLMProcessing && !listeningForQuestion && currentlyScannedButton) {
                    const buttonToActivate = currentlyScannedButton; // Capture the button reference
                    console.log("Gamepad button 0 pressed, activating button:", buttonToActivate.textContent);
                    buttonToActivate.click();
                    buttonToActivate.classList.add('active');
                    // Use the captured reference in the timeout
                    setTimeout(() => buttonToActivate?.classList.remove('active'), 150);
                    lastGamepadInputTime = now;
                } else { console.log("Gamepad press ignored (state)."); }
             } else { console.log("Gamepad press ignored (rate limit)."); }
        }
        lastButtonState = currentButtonState;
        gamepadPollInterval = requestAnimationFrame(pollGamepads); // Continue polling
    }
    gamepadPollInterval = requestAnimationFrame(pollGamepads); // Start the loop
}

/**
 * Stops the gamepad polling loop.
 */
function stopGamepadPolling() {
    if (gamepadPollInterval !== null) {
        cancelAnimationFrame(gamepadPollInterval);
        gamepadPollInterval = null;
        console.log("Stopped gamepad polling.");
    }
}


// --- Utility Functions ---
// Add CSS for scanning highlight (if not already present)
if (!document.getElementById('scanning-styles')) {
    const styleSheet = document.createElement("style");
    styleSheet.id = 'scanning-styles';
    styleSheet.textContent = `
        .scanning { /* Highlight style */
            box-shadow: 0 0 10px 4px #FB4F14 !important; /* Orange glow, !important to override base button shadow */
            outline: none !important; /* Prevent default browser focus outline, !important for specificity */
        }
        .active { /* Optional style for click feedback */
             transform: scale(0.95);
             opacity: 0.8;
        }
        .grid-button-base { /* Ensure base class exists for JS */ }
    `;
    document.head.appendChild(styleSheet);
}

// Add event listener to stop scanning/polling on page unload
window.addEventListener('beforeunload', () => {
    stopAuditoryScanning();
    stopGamepadPolling();
});
